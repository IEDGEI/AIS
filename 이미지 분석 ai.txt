import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from sklearn.metrics import classification_report, f1_score
import matplotlib.pyplot as plt
from google.colab import drive

# Google Drive 연결
drive.mount('/content/drive')

# 데이터 경로 설정 (훈련 및 테스트 데이터 경로)
train_data_dir = '/content/drive/MyDrive/dataset/train'
test_data_dir = '/content/drive/MyDrive/dataset/test'
img_width, img_height = 150, 150  # 이미지 크기 (모델에 입력될 이미지 크기)
batch_size = 32  # 배치 크기
epochs = 20  # 훈련할 에폭 수

# 클래스 이름 (각각의 클래스 라벨에 해당하는 이름)
class_names = ['apple', 'banana', 'orange']

# 파일명에서 클래스 라벨을 추출하는 함수
def extract_class_from_filename(filename):
    if 'apple' in filename:
        return 0  # apple은 클래스 0
    elif 'banana' in filename:
        return 1  # banana는 클래스 1
    elif 'orange' in filename:
        return 2  # orange는 클래스 2
    else:
        return -1  # 라벨을 찾을 수 없는 경우 (예: 이미지 파일에 클래스 정보가 없는 경우)

# 데이터 준비: 디렉토리에서 이미지와 레이블을 로딩하는 함수
def load_data_from_directory(directory, normalize=True):
    images, labels = [], []
    # 디렉토리 내의 파일들을 하나씩 확인
    for filename in os.listdir(directory):
        if filename.endswith('.jpg') or filename.endswith('.jpeg'):
            img_path = os.path.join(directory, filename)
            img = load_img(img_path, target_size=(img_width, img_height))  # 이미지 크기 맞추기
            img = img_to_array(img)  # 이미지를 배열로 변환
            if normalize:
                img = img / 255.0  # 이미지를 0~1 범위로 정규화
            label = extract_class_from_filename(filename)  # 파일명에서 클래스 라벨 추출
            if label != -1:  # 유효한 라벨인 경우만 추가
                images.append(img)
                labels.append(label)
    return np.array(images), np.array(labels)

# 훈련 데이터와 테스트 데이터 로딩
train_images, train_labels = load_data_from_directory(train_data_dir, normalize=False)
test_images, test_labels = load_data_from_directory(test_data_dir, normalize=False)

# ImageDataGenerator를 이용한 데이터 증강 설정
train_datagen = ImageDataGenerator(
    rescale=1./255,  # 이미지 정규화
    shear_range=0.3,  # 전단 변환 (이미지 왜곡)
    zoom_range=0.3,   # 확대/축소
    horizontal_flip=True,  # 수평 반전
    rotation_range=40,  # 회전 (더 넓은 범위로 증강)
    width_shift_range=0.3,  # 가로 이동
    height_shift_range=0.3,  # 세로 이동
    brightness_range=[0.2, 1.8],  # 밝기 조정
)

test_datagen = ImageDataGenerator(rescale=1./255)  # 테스트 데이터는 정규화만 진행

# 증강된 이미지 시각화 함수
def plot_augmented_images(generator, images, labels, class_names, n=5):
    fig, axes = plt.subplots(1, n, figsize=(20, 5))  # 5개의 이미지를 한 줄로 시각화
    for i in range(n):
        idx = np.random.randint(0, len(images))  # 랜덤 이미지 선택
        img = images[idx].reshape(1, img_width, img_height, 3)  # 입력 이미지 형태로 변환
        augmented_img = next(generator.flow(img, batch_size=1))[0]  # 데이터 증강 적용

        # 증강된 이미지를 0~255 범위로 다시 조정
        augmented_img = np.clip(augmented_img * 255, 0, 255).astype('uint8')

        # 이미지를 시각화
        axes[i].imshow(augmented_img)
        axes[i].axis('off')  # 축 숨기기
        axes[i].set_title(f"Class: {class_names[labels[idx]]}")  # 클래스 이름 출력
    plt.tight_layout()  # 레이아웃 조정
    plt.show()

# 훈련 데이터에서 5개의 증강된 이미지 출력
plot_augmented_images(train_datagen, train_images, train_labels, class_names)

# 훈련 데이터 증강 및 배치 생성
train_generator = train_datagen.flow(
    train_images, train_labels, batch_size=batch_size  # 배치 크기만큼 데이터를 생성
)

# 테스트 데이터 증강 및 배치 생성
test_generator = test_datagen.flow(
    test_images, test_labels, batch_size=batch_size  # 테스트 배치 생성
)

# 모델 정의 (CNN 모델)
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),  # 첫 번째 합성곱 층
    tf.keras.layers.MaxPooling2D((2, 2)),  # 풀링 층 (특징을 다운샘플링)
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),  # 두 번째 합성곱 층
    tf.keras.layers.MaxPooling2D((2, 2)),  # 풀링 층
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),  # 세 번째 합성곱 층
    tf.keras.layers.MaxPooling2D((2, 2)),  # 풀링 층
    tf.keras.layers.Flatten(),  # 1D 벡터로 평탄화
    tf.keras.layers.Dense(128, activation='relu'),  # 완전 연결된 층
    tf.keras.layers.Dropout(0.5),  # 드롭아웃 (과적합 방지)
    tf.keras.layers.Dense(len(class_names), activation='softmax')  # 클래스 수만큼 출력, softmax로 확률 계산
])

# 모델 컴파일
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 모델 훈련
history = model.fit(
    train_generator,  # 훈련 데이터
    epochs=epochs,  # 훈련 횟수
    validation_data=test_generator  # 검증 데이터
)

# 모델 평가
loss, accuracy = model.evaluate(test_generator)  # 테스트 데이터에 대해 모델 평가
print(f'Test Loss: {loss}')  # 테스트 손실
print(f'Test Accuracy: {accuracy}')  # 테스트 정확도

# 테스트셋에 대한 예측
y_pred = model.predict(test_generator)  # 예측 결과 (확률)
y_pred = np.argmax(y_pred, axis=1)  # 가장 높은 확률을 가진 클래스를 예측 결과로 선택
y_true = test_labels  # 실제 클래스

# 분류 리포트 및 F1 Score 계산
report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)  # 분류 리포트 출력
print("Classification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))  # 분류 리포트 출력

f1 = f1_score(y_true, y_pred, average='weighted')  # 가중 평균 F1 Score 계산
print(f'Weighted F1 Score: {f1 * 100:.2f}%')  # 가중 F1 Score 출력

# 전체 정확도 추가 출력
overall_accuracy = report['accuracy']  # classification_report 출력에서 "accuracy" 키 사용
print(f'Overall Accuracy (from classification report): {overall_accuracy * 100:.2f}%')
